"""
The ``RhinoTSplines`` module
----------------------------
is a proof-of-concept implementation of generating ``tIGArx``-type extraction
data from the output of commercial CAD software.  In particular, it reads
data generated by the (now defunct) Rhino T-splines plugin.
"""

import numpy as np
import numba as nb



import dolfinx
import basix
import ufl

from mpi4py import MPI

from tigarx.BSplines import AbstractScalarBasis, AbstractControlMesh, worldcomm
from tigarx.utils import interleave_and_expand, get_csr_pre_allocation
from dolfinx import default_real_type

# important case of output from Rhino T-splines plugin: bi-variate cubic
# Bezier elements


# cubic Bernstein basis on -1 to 1 interval
def Bernstein_p3(u):
    """
    Because Rhino outputs element-by-element extraction data assuming a
    Bezier basis on each element, we evaluate T-spline basis functions
    in terms of Bezier basis functions (even though we are extracting to
    Lagrange elements).  This function returns a list of the four cubic
    Bernstein polynomials on (-1,1) evaluated at parameter ``u`` in that
    interval.
    """
    # re-use B-spline machinery
    # knots = [-1.0,-1.0,-1.0,-1.0,1.0,1.0,1.0,1.0]
    # spline = BSpline1(3,knots)
    # return spline.basisFuncs(3,u)
    B = [0.0, 0.0, 0.0, 0.0]
    x = 0.5 * (1.0 + u)
    B[0] = (1.0 - x) ** 3
    B[1] = 3.0 * x * ((1.0 - x) ** 2)
    B[2] = 3.0 * (x**2) * (1.0 - x)
    B[3] = x**3
    return B


def RhinoTSplineScalarBasisFuncs(xi, C):
    """
    Use the Berstein basis functions and a Rhino-format extraction operator
    ``C`` to evaluate T-spline basis functions at parameters ``xi`` in
    a Bezier element parameterized by (-1,1)^2.

    Rhino's format:  ``C`` is a matrix in which each row specifies a
    linear combination of Bezier shape functions.
    """
    u = xi[0]
    v = xi[1]
    M = Bernstein_p3(u)
    N = Bernstein_p3(v)
    Bern = []
    for j in range(0, 4):
        for i in range(0, 4):
            Bern += [
                M[i] * N[j],
            ]
    tmpshl = []
    for aa in range(0, len(C)):
        tmpshlaa = 0.0
        for bb in range(0, 16):
            tmpshlaa += C[aa][bb] * Bern[bb]
        tmpshl += [
            tmpshlaa,
        ]
    return tmpshl


def identity_partitioner(
    comm: MPI.Comm,
    nparts: int,
    cell_types: list[int],
    topo: dolfinx.cpp.graph.AdjacencyList_int64,
) -> dolfinx.cpp.graph.AdjacencyList_int32:
    """(Dummy) mesh partitioner for leaving cells on the current rank.

    Args:
        comm: Mesh's MPI communicator
        nparts: Number of parts in which the mesh will be partitioned.
        cell_types: Cell types of the mesh.
        topo: Topology to distribute.

    Returns:
        rank_dest: Adjaceny list assigning to every cell in the list cells,
        the MPI rank of destination.
        In this case, the destination rank will be the current one.
    """

    assert len(cell_types) == len(topo)
    assert len(topo) == 1, "Not implemented for multiple groups of cells."

    n_cells = len(topo[0]) // dolfinx.cpp.mesh.cell_num_vertices(cell_types[0])
    rank_dest = np.full(n_cells, comm.rank, dtype=np.int32)
    rank_dest = dolfinx.cpp.graph.AdjacencyList_int32(rank_dest)
    return rank_dest


# Implementation: get everything covered by one coordinate chart,
# space out elements so that element i goes from 3.0*i to 3.0*i+2.0
# in x0 direction.  Thus, if we round down (x0/3.0 + EPS), it returns
# the element index, and we have u = x0 - 3.0*i - 1.0, v = x1 for
# eval-ing shape functions
class RhinoTSplineScalarBasis(AbstractScalarBasis):

    def __init__(self, fname):
        """
        Generates an instance of ``RhinoTSplineScalarBasis`` from
        element-by-element extraction data in the file ``fname``.
        """
        self.nvar = 2
        # read in a T-spline patch from file fname
        # TODO: do this efficiently w/ numpy arrays instead of py lists
        f = open(fname, "r")
        fs = f.read()
        f.close()
        lines = fs.split("\n")
        self.ncp = int(lines[1].split()[1])
        self.nelBez = int(lines[2].split()[1])

        # Changed for true format
        # lineCounter = 4+self.ncp
        lineCounter = 3 + self.ncp

        self.extractionOperators = []
        self.extractionNodes = []
        self.maxNshl = 0
        for i in range(0, self.nelBez):
            nshl = int(lines[lineCounter].split()[1])
            if nshl > self.maxNshl:
                self.maxNshl = nshl
            nodeStrings = lines[lineCounter + 1].split()
            nodes = []
            for ns in nodeStrings:
                nodes += [
                    int(ns),
                ]
            self.extractionNodes += [
                nodes,
            ]
            C = []
            for j in range(0, nshl):
                coeffStrings = lines[lineCounter + 2 + j].split()
                coeffs = []
                for cs in coeffStrings:
                    coeffs += [
                        float(cs),
                    ]
                C += [
                    coeffs,
                ]
            lineCounter += nshl + 2
            self.extractionOperators += [
                C,
            ]

        # TODO: read in BC info

    # def getParametricDimension(self):
    #    return self.nvar

    def getPrealloc(self):
        return self.maxNshl

    def is_tensor_product_basis(self) -> bool:
        return False

    def needsDG(self):
        # Even if using discontinuous meshes, somehow dolfinx detects coincident
        # nodes and creates continuous spaces by default.
        # In this way we force the use of DG elements.
        return True

    def getNodesAndEvals(self, xi):
        elementIndex = int(xi[0] / 3.0 + 0.1)
        u = xi[0] - 3.0 * elementIndex - 1.0
        v = xi[1]
        C = self.extractionOperators[elementIndex]
        nodes = self.extractionNodes[elementIndex]
        evals = RhinoTSplineScalarBasisFuncs([u, v], C)
        nodesAndEvals = []
        for i in range(0, len(nodes)):
            nodesAndEvals += [
                [nodes[i], evals[i]],
            ]
        return nodesAndEvals

    def generateMesh(self, comm=worldcomm):

        rank = comm.rank
        assert rank <= self.nelBez, "There are more MPI processes than Beziers."

        process_cells = np.array_split(range(self.nelBez), comm.size)[rank]
        nelBez_proc = process_cells.size

        coords = np.zeros((nelBez_proc * 2, 2, 2), dtype=default_real_type)
        x = np.array([[3 * cell_id, 3*cell_id+2] for cell_id in process_cells]
                     ).flatten().astype(default_real_type)
        coords[:, 0, 0] = x[:]
        coords[:, 1, 0] = x[:]
        coords[:, 0, 1] = -1.0
        coords[:, 1, 1] = 1.0
        coords = coords.reshape(-1, 2)

        coords_offset = process_cells[0] * 4
        conn = np.arange(coords.shape[0]).reshape(
            (nelBez_proc, 4)) + coords_offset

        domain = ufl.Mesh(basix.ufl.element(
            "Lagrange", "quadrilateral", 1, shape=(2,), discontinuous=True))

        # Note: an user-defined (identity) partitioner
        # is required here as ParMetis fails in partitioning
        # non-connected meshes.
        mesh = dolfinx.mesh.create_mesh(
            comm, conn.tolist(), coords, domain, partitioner=identity_partitioner)

        return mesh

    def getNcp(self):
        return self.ncp

    def getDegree(self):
        return 3

    def getCpDofmap(self, cells: np.ndarray | None = None, block_size=1) -> np.ndarray:
        dofmap = nb.typed.List()
        for i, nodes in enumerate(self.extractionNodes):
            temp_dofs = np.array(nodes, dtype=np.int32)
            dofmap.append(
                np.array(interleave_and_expand(temp_dofs, block_size), dtype=np.int32)
            )

        return dofmap

    def get_lagrange_extraction_operators(self) -> list[np.ndarray]:
        operator_arr = nb.typed.List()
        for i in range(self.nelBez):
            op = np.array(self.extractionOperators[i])[np.newaxis, :, :]
            operator_arr.append(np.ascontiguousarray(op))

        return operator_arr

    def getElement(self, xi):
        return int(xi[0] / 3.0 + 0.1)

    def getCSRPrealloc(self, block_size=1) -> tuple[np.ndarray, np.ndarray]:
        cells = np.arange(len(self.extractionNodes), dtype=np.int32)
        dofmap = self.getCpDofmap(cells, block_size)
        dimension = self.getNcp() * block_size
        max_dofs_per_row = block_size * (2 * self.getDegree() + 1) ** 2

        return get_csr_pre_allocation(cells, dofmap, dimension, max_dofs_per_row)

    def getNumLocalDofs(self, block_size=1) -> np.ndarray:
        num_dofs = np.zeros(self.nelBez, dtype=np.int32)
        for i in range(self.nelBez):
            num_dofs[i] = len(self.extractionNodes[i]) * block_size

        return num_dofs


class RhinoTSplineControlMesh(AbstractControlMesh):
    """
    This class uses a ``RhinoTSplineScalarBasis`` and control point data
    from Rhino to represent a mapping from parametric to physical space.
    """

    def __init__(self, fname):
        """
        Initialize a control mesh by reading extraction data and control
        points from a Rhino T-spline file named ``fname``.
        """
        self.scalarSpline = RhinoTSplineScalarBasis(fname)
        self.nsd = 3
        # read in control net from fname
        f = open(fname, "r")
        fs = f.read()
        f.close()

        lines = fs.split("\n")
        nnode = self.scalarSpline.getNcp()
        self.bnet = np.zeros((nnode, self.nsd + 1))
        for i in range(0, nnode):
            # for manually-modified format
            # ii = i + 4
            # for files directly from rhino
            ii = i + 3
            coordStrs = lines[ii].split()
            for j in range(0, self.nsd + 1):
                self.bnet[i, j] = float(coordStrs[j + 1])
        # homogenize
        for i in range(0, nnode):
            for j in range(0, self.nsd):
                self.bnet[i, j] *= self.bnet[i, self.nsd]

    def getHomogeneousCoordinate(self, node, direction):
        return self.bnet[node, direction]

    def getScalarSpline(self):
        return self.scalarSpline

    def getNsd(self):
        return self.nsd

    def get_all_control_points(self) -> np.ndarray:
        return self.bnet
